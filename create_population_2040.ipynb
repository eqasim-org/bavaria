{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934d032c",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "In this notebook, we generate the projected population for the year 2043 for the regions of Upper Bavaria (Oberbayern), Lower Bavaria (Niederbayern), and Swabia (Schwaben), using data from the official report:\n",
    "https://www.statistik.bayern.de/mam/statistik/gebiet_bevoelkerung/demographischer_wandel/demographische_profile/region14.pdf, pages 20–21.\n",
    "\n",
    "\n",
    "#### Approach:\n",
    "We first extract the projected population figures for 2043 for each \"Gemeinde\" as provided in the report. Then, we calculate the share of each \"Kommune\" within its \"Gemeinde\" and apply these shares to the 2024 census data to distribute the projected population accordingly.\n",
    "\n",
    "Next, using the age and sex distributions from the 2024 census, we estimate how the 2043 population is distributed across all age–sex combinations. These proportions are scaled up to match the total 2043 population.\n",
    "\n",
    "Finally, we integrate city-level data for Munich, which provide more accurate information by age group, as there's a separate report on this. These data were generated separately in the notebook “create_population_2040_munich.ipynb”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de761d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct comune ids: 1098\n",
      "In total, the population for Oberbayern, Niederbayern and Schwaben is: 7957065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- 1) Read the Data ---\n",
    "census_2024_df = pd.read_csv(\"census_data_2024.csv\", sep=\",\", dtype={\"commune_id\": str})  # keep strings as strings\n",
    "n_distinct = census_2024_df.iloc[:, 0].nunique(dropna=True)\n",
    "print(\"Number of distinct comune ids:\", n_distinct)\n",
    "print(\"In total, the population for Oberbayern, Niederbayern and Schwaben is:\", census_2024_df['weight'].sum())\n",
    "population_2045 = pd.read_csv(\"pop_oberbayern_niederbayern_schwaben_2043_raw.csv\", sep=\",\", dtype={\"kommunen_id_start\": str})\n",
    "processed_pop_munich_2045 = pd.read_csv(\"pop_munich_2045_processed.csv\", dtype={\"kommunen_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f28a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure types are as expected\n",
    "census_2024_df[\"commune_id\"] = census_2024_df[\"commune_id\"].astype(str).str.strip()\n",
    "census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows without an ID\n",
    "census_2024_df = census_2024_df[census_2024_df[\"commune_id\"].notna() & (census_2024_df[\"commune_id\"] != \"\")]\n",
    "\n",
    "# Build: commune_id -> total population (sum of weights)\n",
    "census_2_pop = (\n",
    "    census_2024_df.groupby(\"commune_id\", dropna=False)[\"weight\"]\n",
    "             .sum(min_count=1)         # keeps NaN if all weights were NaN for an ID\n",
    "             .fillna(0)                # optional: treat all-NaN as 0\n",
    "             .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Helpers --------------------\n",
    "def normalize_id(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Return 12-digit string IDs (digits only, left-padded). Drop invalid.\"\"\"\n",
    "    s = (series.astype(str)\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\D\", \"\", regex=True)\n",
    "               .str.zfill(12))\n",
    "    return s.where(s.str.fullmatch(r\"\\d{12}\"))\n",
    "\n",
    "# -------------------- Inputs --------------------\n",
    "population_2045 = population_2045[[\"kommunen_id_start\",\"Name_norm\",\"population_2043_abs\"]].copy()\n",
    "\n",
    "try:\n",
    "    census_2_pop  # dict exists\n",
    "except NameError:\n",
    "    # Build from census_df\n",
    "    census_2024_df = pd.read_csv(\"census_data_2024.csv\", dtype={\"commune_id\": str})\n",
    "    census_2024_df[\"commune_id_norm\"] = normalize_id(census_2024_df[\"commune_id\"])\n",
    "    census_2024_df = census_2024_df[census_2024_df[\"commune_id_norm\"].notna()].copy()\n",
    "    census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Sum weights per commune (current population by commune)\n",
    "    census_2_pop = (census_2024_df.groupby(\"commune_id_norm\")[\"weight\"]\n",
    "                    .sum(min_count=1).fillna(0).to_dict())\n",
    "\n",
    "# -------------------- Build commune-level frame --------------------\n",
    "# Turn census_2_pop dict into a DataFrame\n",
    "commune_now = (pd.Series(census_2_pop, name=\"population_2024_kommune\")\n",
    "               .rename_axis(\"kommunen_id\")  # 12-digit id\n",
    "               .reset_index())\n",
    "\n",
    "# Derive 5-digit prefix for each commune\n",
    "commune_now[\"kommunen_id\"] = normalize_id(commune_now[\"kommunen_id\"])\n",
    "commune_now = commune_now[commune_now[\"kommunen_id\"].notna()].copy()\n",
    "commune_now[\"kommunen_id_start\"] = commune_now[\"kommunen_id\"].str[:5]\n",
    "\n",
    "# -------------------- Aggregate current pop by prefix --------------------\n",
    "grp_now = (commune_now.groupby(\"kommunen_id_start\", dropna=True)[\"population_2024_kommune\"]\n",
    "           .sum(min_count=1).rename(\"population_2024_gemeinde\")\n",
    "           .reset_index())\n",
    "\n",
    "# Attach the group total and the PDF 2043 totals & name (by prefix)\n",
    "work = (commune_now\n",
    "        .merge(grp_now, on=\"kommunen_id_start\", how=\"left\")\n",
    "        .merge(population_2045.rename(columns={\"population_2043_abs\":\"population_2043_gemeinde\",\n",
    "                                               \"Name_norm\":\"name\"}),\n",
    "               on=\"kommunen_id_start\", how=\"left\"))\n",
    "\n",
    "# -------------------- Compute shares & scaled 2043 --------------------\n",
    "# Guard against division by zero: if the group total is 0 or NaN, set share=0 and scaled=0\n",
    "den = work[\"population_2024_gemeinde\"].replace({0: np.nan})\n",
    "share = work[\"population_2024_kommune\"] / den\n",
    "work[\"weight_of_single_kommune_among_gemeinde\"] = (share.fillna(0) * 100)  # percent\n",
    "work[\"population_2043_gemeinde\"] = pd.to_numeric(work[\"population_2043_gemeinde\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "work[\"scaled_population_2043_kommune\"] = (\n",
    "    work[\"population_2043_gemeinde\"] * (work[\"weight_of_single_kommune_among_gemeinde\"] / 100.0)\n",
    ").round(0).astype(int)\n",
    "\n",
    "# -------------------- Final columns & save --------------------\n",
    "result = work[[\n",
    "    \"kommunen_id\",                        # 12-digit\n",
    "    \"kommunen_id_start\",                  # 5-digit prefix\n",
    "    \"name\",                               # from the prefix row\n",
    "    \"population_2024_kommune\",            # current pop by commune (from census_2_pop)\n",
    "    \"population_2024_gemeinde\",           # sum over the prefix\n",
    "    \"weight_of_single_kommune_among_gemeinde\",  # percent\n",
    "    \"population_2043_gemeinde\",           # PDF 2043 per prefix\n",
    "    \"scaled_population_2043_kommune\"      # allocated 2043 per commune\n",
    "]].copy()\n",
    "\n",
    "# Optional: tidy types / rounding\n",
    "result[\"weight_of_single_kommune_among_gemeinde\"] = result[\"weight_of_single_kommune_among_gemeinde\"].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f1cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cleaned = result[[\"kommunen_id\", \"population_2024_kommune\", \"scaled_population_2043_kommune\"]]\n",
    "result_cleaned = result_cleaned.rename(\n",
    "    columns={\n",
    "        \"population_2024_kommune\": \"pop_2024\",\n",
    "        \"scaled_population_2043_kommune\": \"pop_2043\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc46791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Helpers --------------------\n",
    "def normalize_id(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Return 12-digit string IDs (digits only, left-padded). Drop invalid.\"\"\"\n",
    "    s = (series.astype(str)\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\D\", \"\", regex=True)\n",
    "               .str.zfill(12))\n",
    "    return s.where(s.str.fullmatch(r\"\\d{12}\"))\n",
    "\n",
    "# -------------------- Inputs --------------------\n",
    "# result_cleaned must have: kommunen_id, pop_2024, pop_2043\n",
    "# census_df must have: commune_id, sex, age_class, weight\n",
    "# If you already have them in memory, you can skip these reads.\n",
    "# result_cleaned = pd.read_csv(\"result_cleaned.csv\", dtype={\"kommunen_id\": str})\n",
    "# census_df = pd.read_csv(\"census_data.csv\", dtype={\"commune_id\": str})\n",
    "\n",
    "# --- Normalize IDs and clean types\n",
    "result_cleaned[\"kommunen_id\"] = normalize_id(result_cleaned[\"kommunen_id\"])\n",
    "result_cleaned = result_cleaned[result_cleaned[\"kommunen_id\"].notna()].copy()\n",
    "\n",
    "census_2024_df[\"commune_id_norm\"] = normalize_id(census_2024_df[\"commune_id\"])\n",
    "census_2024_df = census_2024_df[census_2024_df[\"commune_id_norm\"].notna()].copy()\n",
    "census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -------------------- 1) Enumerate the 26 combinations --------------------\n",
    "all_combos = (\n",
    "    census_2024_df[[\"sex\", \"age_class\"]]\n",
    "      .drop_duplicates()\n",
    "      .sort_values([\"sex\", \"age_class\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "# Sanity: we expect 26 distinct combos total\n",
    "n_combos = len(all_combos)\n",
    "if n_combos != 26:\n",
    "    print(f\"WARNING: expected 26 (sex, age_class) combos, found {n_combos}. Proceeding with found combos.\")\n",
    "\n",
    "# -------------------- 2) Compute per-(commune_id, combo) weights & fractions --------------------\n",
    "combo_weights = (\n",
    "    census_2024_df\n",
    "      .groupby([\"commune_id_norm\", \"sex\", \"age_class\"], dropna=False)[\"weight\"]\n",
    "      .sum(min_count=1)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "totals_per_commune = (\n",
    "    combo_weights\n",
    "      .groupby(\"commune_id_norm\", dropna=False)[\"weight\"]\n",
    "      .sum(min_count=1)\n",
    "      .rename(\"total_weight_commune\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "combo_weights = combo_weights.merge(totals_per_commune, on=\"commune_id_norm\", how=\"left\")\n",
    "\n",
    "# Fraction per combo (guard against division by zero)\n",
    "combo_weights[\"fraction_2024\"] = (\n",
    "    combo_weights[\"weight\"] / combo_weights[\"total_weight_commune\"].replace({0: np.nan})\n",
    ").fillna(0.0)\n",
    "\n",
    "# -------------------- 3) Ensure every commune has all combos (fill missing with 0) --------------------\n",
    "communes = result_cleaned[[\"kommunen_id\"]].drop_duplicates().rename(columns={\"kommunen_id\": \"commune_id_norm\"})\n",
    "grid = communes.assign(key=1).merge(all_combos.assign(key=1), on=\"key\").drop(columns=\"key\")\n",
    "\n",
    "grid = grid.merge(\n",
    "    combo_weights[[\"commune_id_norm\", \"sex\", \"age_class\", \"fraction_2024\"]],\n",
    "    on=[\"commune_id_norm\", \"sex\", \"age_class\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "grid[\"fraction_2024\"] = grid[\"fraction_2024\"].fillna(0.0)\n",
    "\n",
    "# -------------------- 4) Expand result_cleaned (26 rows per commune) and scale pops --------------------\n",
    "expanded = (\n",
    "    grid.merge(\n",
    "        result_cleaned.rename(columns={\"kommunen_id\": \"commune_id_norm\"}),\n",
    "        on=\"commune_id_norm\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "expanded[\"pop_2024_by_combo\"] = expanded[\"pop_2024\"] * expanded[\"fraction_2024\"]\n",
    "expanded[\"pop_2043_by_combo\"] = expanded[\"pop_2043\"] * expanded[\"fraction_2024\"]\n",
    "\n",
    "# -------------------- 5) Validations --------------------\n",
    "# A) Fractions per commune should sum to 1 (or 0 if truly no data and no fallback)\n",
    "frac_sums = expanded.groupby(\"commune_id_norm\")[\"fraction_2024\"].sum().reset_index()\n",
    "bad_fracs = frac_sums[~np.isclose(frac_sums[\"fraction_2024\"], 1.0, atol=1e-8) & (frac_sums[\"fraction_2024\"] != 0)]\n",
    "if not bad_fracs.empty:\n",
    "    print(\"WARNING: Some communes have fractions not summing to 1 (and not 0). Examples:\")\n",
    "    print(bad_fracs.head())\n",
    "\n",
    "# B) Check that sums of distributed pops match originals (within tolerance)\n",
    "check_2024 = (\n",
    "    expanded.groupby(\"commune_id_norm\")[\"pop_2024_by_combo\"].sum().reset_index()\n",
    "    .merge(result_cleaned.rename(columns={\"kommunen_id\":\"commune_id_norm\"})[[\"commune_id_norm\",\"pop_2024\"]],\n",
    "           on=\"commune_id_norm\", how=\"left\")\n",
    ")\n",
    "check_2024[\"diff_2024\"] = check_2024[\"pop_2024_by_combo\"] - check_2024[\"pop_2024\"]\n",
    "if not np.allclose(check_2024[\"diff_2024\"], 0.0, atol=1e-6, rtol=1e-10):\n",
    "    print(\"WARNING: pop_2024_by_combo does not perfectly sum back to pop_2024 for some communes.\")\n",
    "\n",
    "check_2043 = (\n",
    "    expanded.groupby(\"commune_id_norm\")[\"pop_2043_by_combo\"].sum().reset_index()\n",
    "    .merge(result_cleaned.rename(columns={\"kommunen_id\":\"commune_id_norm\"})[[\"commune_id_norm\",\"pop_2043\"]],\n",
    "           on=\"commune_id_norm\", how=\"left\")\n",
    ")\n",
    "check_2043[\"diff_2043\"] = check_2043[\"pop_2043_by_combo\"] - check_2043[\"pop_2043\"]\n",
    "if not np.allclose(check_2043[\"diff_2043\"], 0.0, atol=1e-6, rtol=1e-10):\n",
    "    print(\"WARNING: pop_2043_by_combo does not perfectly sum back to pop_2043 for some communes.\")\n",
    "\n",
    "# -------------------- 6) Final tidy --------------------\n",
    "result_expanded = expanded[[\n",
    "    \"commune_id_norm\",  # == kommunen_id (12 digits)\n",
    "    \"sex\",\n",
    "    \"age_class\",\n",
    "    \"fraction_2024\",\n",
    "    \"pop_2024_by_combo\",\n",
    "    \"pop_2043_by_combo\",\n",
    "    \"pop_2024\",\n",
    "    \"pop_2043\",\n",
    "]].rename(columns={\"commune_id_norm\": \"kommunen_id\"})\n",
    "\n",
    "# (Optional) Round to integers if you need person counts:\n",
    "# result_expanded[\"pop_2024_by_combo\"] = result_expanded[\"pop_2024_by_combo\"].round(0).astype(int)\n",
    "# result_expanded[\"pop_2043_by_combo\"] = result_expanded[\"pop_2043_by_combo\"].round(0).astype(int)\n",
    "\n",
    "# Save if desired\n",
    "# result_expanded.to_csv(\"result_expanded_26_combos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aced7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = result_expanded.rename(\n",
    "    columns={\n",
    "        \"kommunen_id\": \"commune_id\",\n",
    "        \"pop_2043_by_combo\": \"weight\",\n",
    "    }\n",
    ")\n",
    "final_result=final_result[[\"commune_id\", \"sex\",\"age_class\",\"weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4952ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct sex in result_final: ['female', 'male']\n",
      "Distinct sex in updates_long: ['female', 'male']\n",
      "Potential key matches: 26 out of 26 update keys and 28548 result keys\n",
      "Rows that will be updated: 26\n",
      "        sum_in_result_final  sum_from_updates\n",
      "sex                                          \n",
      "female               932273            932273\n",
      "male                 897248            897248\n"
     ]
    }
   ],
   "source": [
    "# ---------- Helpers ----------\n",
    "def normalize_id(s: pd.Series) -> pd.Series:\n",
    "    return (s.astype(str).str.strip().str.replace(r\"\\D\", \"\", regex=True).str.zfill(12))\n",
    "\n",
    "def normalize_sex(s: pd.Series) -> pd.Series:\n",
    "    # map a variety of spellings to {'female','male'}; everything else -> lowercased as-is\n",
    "    mapping = {\n",
    "        \"f\":\"female\",\"w\":\"female\",\"weiblich\":\"female\",\"female\":\"female\",\n",
    "        \"m\":\"male\",\"mann\":\"male\",\"maennlich\":\"male\",\"männlich\":\"male\",\"male\":\"male\"\n",
    "    }\n",
    "    return s.astype(str).str.strip().str.lower().map(mapping).fillna(s.astype(str).str.strip().str.lower())\n",
    "\n",
    "# ---------- 0) Make safe copies ----------\n",
    "result_final = final_result.copy()\n",
    "processed_pop_munich_2045 = processed_pop_munich_2045.copy()\n",
    "\n",
    "# ---------- 1) Normalize keys / types ----------\n",
    "# result_final\n",
    "if \"kommunen_id\" in result_final.columns and \"commune_id\" not in result_final.columns:\n",
    "    result_final = result_final.rename(columns={\"kommunen_id\":\"commune_id\"})\n",
    "result_final[\"commune_id\"] = normalize_id(result_final[\"commune_id\"])\n",
    "result_final[\"sex\"] = normalize_sex(result_final[\"sex\"])\n",
    "result_final[\"age_class\"] = pd.to_numeric(result_final[\"age_class\"], errors=\"coerce\").astype(\"Int64\")\n",
    "result_final[\"weight\"] = pd.to_numeric(result_final[\"weight\"], errors=\"coerce\")\n",
    "\n",
    "# processed_pop_munich_2045\n",
    "processed_pop_munich_2045[\"commune_id\"] = normalize_id(processed_pop_munich_2045[\"commune_id\"])\n",
    "processed_pop_munich_2045[\"age_start\"] = pd.to_numeric(processed_pop_munich_2045[\"age_start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ---------- 2) Reshape Munich table to long by sex ----------\n",
    "updates_long = (\n",
    "    processed_pop_munich_2045\n",
    "      .melt(id_vars=[\"commune_id\",\"age_start\"],\n",
    "            value_vars=[\"female_2045\",\"male_2045\"],\n",
    "            var_name=\"sex_var\", value_name=\"weight_new\")\n",
    "      .assign(sex=lambda df: df[\"sex_var\"].str.replace(\"_2045\",\"\",regex=False))\n",
    "      .rename(columns={\"age_start\":\"age_class\"})\n",
    "      [[\"commune_id\",\"sex\",\"age_class\",\"weight_new\"]]\n",
    ")\n",
    "\n",
    "# If there are accidental duplicates per key, collapse them (sum)\n",
    "updates_long = (updates_long\n",
    "                .groupby([\"commune_id\",\"sex\",\"age_class\"], as_index=False)[\"weight_new\"]\n",
    "                .sum())\n",
    "\n",
    "# ---------- 3) Check key alignment BEFORE merge ----------\n",
    "print(\"Distinct sex in result_final:\", sorted(result_final[\"sex\"].dropna().unique())[:10])\n",
    "print(\"Distinct sex in updates_long:\", sorted(updates_long[\"sex\"].dropna().unique())[:10])\n",
    "\n",
    "rf_keys = set(zip(result_final[\"commune_id\"], result_final[\"sex\"], result_final[\"age_class\"]))\n",
    "up_keys = set(zip(updates_long[\"commune_id\"], updates_long[\"sex\"], updates_long[\"age_class\"]))\n",
    "matches = rf_keys & up_keys\n",
    "print(\"Potential key matches:\", len(matches), \"out of\", len(up_keys), \"update keys and\", len(rf_keys), \"result keys\")\n",
    "\n",
    "if len(matches) == 0:\n",
    "    # Show a few example keys that fail to match\n",
    "    only_in_updates = list(up_keys - rf_keys)[:10]\n",
    "    only_in_result  = list(rf_keys - up_keys)[:10]\n",
    "    print(\"Examples of update keys not in result_final:\", only_in_updates)\n",
    "    print(\"Examples of result_final keys not in updates:\", only_in_result)\n",
    "\n",
    "# ---------- 4) Merge & overwrite weight where we have a match ----------\n",
    "merged = result_final.merge(\n",
    "    updates_long,\n",
    "    on=[\"commune_id\",\"sex\",\"age_class\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep old for reference if you want:\n",
    "# merged[\"weight_old\"] = merged[\"weight\"]\n",
    "\n",
    "updated_count = merged[\"weight_new\"].notna().sum()\n",
    "print(\"Rows that will be updated:\", updated_count)\n",
    "\n",
    "merged[\"weight\"] = np.where(merged[\"weight_new\"].notna(), merged[\"weight_new\"], merged[\"weight\"])\n",
    "merged = merged.drop(columns=[\"weight_new\"])\n",
    "\n",
    "# This is your updated result_final:\n",
    "result_final = merged\n",
    "result_final[\"weight\"] = result_final[\"weight\"].astype(int)\n",
    "\n",
    "# --- Optional: verify Munich totals match the source after update\n",
    "muc_id = \"091620000000\"\n",
    "check = (\n",
    "    result_final[result_final[\"commune_id\"] == muc_id]\n",
    "      .groupby(\"sex\")[\"weight\"].sum()\n",
    "      .rename(\"sum_in_result_final\")\n",
    "      .to_frame()\n",
    "      .join(\n",
    "          updates_long[updates_long[\"commune_id\"] == muc_id]\n",
    "            .groupby(\"sex\")[\"weight_new\"].sum()\n",
    "            .rename(\"sum_from_updates\"),\n",
    "          how=\"left\"\n",
    "      )\n",
    ")\n",
    "print(check)\n",
    "\n",
    "# final_result_2 = result_final.copy()\n",
    "# subset = final_result_2[final_result_2[\"commune_id\"] == \"091620000000\"]\n",
    "\n",
    "result_final.to_csv(\"census_data_2043.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
