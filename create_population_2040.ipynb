{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de761d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct comune ids: 1098\n",
      "In total, the population for Oberbayern, Niederbayern and Schwaben is: 8021702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# This is for all bavaria, the other notebook is for munich only.\n",
    "\n",
    "# --- 1) Read the Data ---\n",
    "census_2024_df = pd.read_csv(\"census_data.csv\", sep=\",\", dtype={\"commune_id\": str})  # keep strings as strings\n",
    "n_distinct = census_2024_df.iloc[:, 0].nunique(dropna=True)\n",
    "print(\"Number of distinct comune ids:\", n_distinct)\n",
    "print(\"In total, the population for Oberbayern, Niederbayern and Schwaben is:\", census_2024_df['weight'].sum())\n",
    "# mask_munich = census_df[\"commune_id\"].astype(str).str.startswith(\"9162\")\n",
    "# total_weight = census_df.loc[mask_munich, \"weight\"].sum(min_count=1)  # returns NaN if none match\n",
    "# print(\"There are \", total_weight, \" people in Munich\")\n",
    "\n",
    "# sex_weights_df = census_df[mask_munich]\n",
    "# age_classes_target_classes = sorted(census_df.loc[mask_munich, \"age_class\"].unique())\n",
    "population_2045 = pd.read_csv(\"population_oberbayern_niederbayern_schwaben_2043.csv\", sep=\",\", dtype={\"kommunen_id_start\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f28a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure types are as expected\n",
    "census_2024_df[\"commune_id\"] = census_2024_df[\"commune_id\"].astype(str).str.strip()\n",
    "census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows without an ID\n",
    "census_2024_df = census_2024_df[census_2024_df[\"commune_id\"].notna() & (census_2024_df[\"commune_id\"] != \"\")]\n",
    "\n",
    "# Build: commune_id -> total population (sum of weights)\n",
    "census_2_pop = (\n",
    "    census_2024_df.groupby(\"commune_id\", dropna=False)[\"weight\"]\n",
    "             .sum(min_count=1)         # keeps NaN if all weights were NaN for an ID\n",
    "             .fillna(0)                # optional: treat all-NaN as 0\n",
    "             .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Helpers --------------------\n",
    "def normalize_id(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Return 12-digit string IDs (digits only, left-padded). Drop invalid.\"\"\"\n",
    "    s = (series.astype(str)\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\D\", \"\", regex=True)\n",
    "               .str.zfill(12))\n",
    "    return s.where(s.str.fullmatch(r\"\\d{12}\"))\n",
    "\n",
    "# -------------------- Inputs --------------------\n",
    "# 1) population_2045: one row per 5-digit prefix\n",
    "#    Must have columns: kommunen_id_start (str), Name_norm (str), population_2043_abs (int)\n",
    "# population_2045 = pd.read_csv(\n",
    "#     \"kommunen_oberbayern_niederbayern_schwaben_2043_with_names_start_only.csv\",\n",
    "#     dtype={\"kommunen_id_start\": str}\n",
    "population_2045 = population_2045[[\"kommunen_id_start\",\"Name_norm\",\"population_2043_abs\"]].copy()\n",
    "\n",
    "# 2) census input: either a dict census_2_pop or a census_df to build it\n",
    "# If you already have census_2_pop, comment out the block that builds it.\n",
    "\n",
    "try:\n",
    "    census_2_pop  # dict exists\n",
    "except NameError:\n",
    "    # Build from census_df\n",
    "    census_2024_df = pd.read_csv(\"census_data_2024.csv\", dtype={\"commune_id\": str})\n",
    "    census_2024_df[\"commune_id_norm\"] = normalize_id(census_2024_df[\"commune_id\"])\n",
    "    census_2024_df = census_2024_df[census_2024_df[\"commune_id_norm\"].notna()].copy()\n",
    "    census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Sum weights per commune (current population by commune)\n",
    "    census_2_pop = (census_2024_df.groupby(\"commune_id_norm\")[\"weight\"]\n",
    "                    .sum(min_count=1).fillna(0).to_dict())\n",
    "\n",
    "# -------------------- Build commune-level frame --------------------\n",
    "# Turn census_2_pop dict into a DataFrame\n",
    "commune_now = (pd.Series(census_2_pop, name=\"population_2024_kommune\")\n",
    "               .rename_axis(\"kommunen_id\")  # 12-digit id\n",
    "               .reset_index())\n",
    "\n",
    "# Derive 5-digit prefix for each commune\n",
    "commune_now[\"kommunen_id\"] = normalize_id(commune_now[\"kommunen_id\"])\n",
    "commune_now = commune_now[commune_now[\"kommunen_id\"].notna()].copy()\n",
    "commune_now[\"kommunen_id_start\"] = commune_now[\"kommunen_id\"].str[:5]\n",
    "\n",
    "# -------------------- Aggregate current pop by prefix --------------------\n",
    "grp_now = (commune_now.groupby(\"kommunen_id_start\", dropna=True)[\"population_2024_kommune\"]\n",
    "           .sum(min_count=1).rename(\"population_2024_gemeinde\")\n",
    "           .reset_index())\n",
    "\n",
    "# Attach the group total and the PDF 2043 totals & name (by prefix)\n",
    "work = (commune_now\n",
    "        .merge(grp_now, on=\"kommunen_id_start\", how=\"left\")\n",
    "        .merge(population_2045.rename(columns={\"population_2043_abs\":\"population_2043_gemeinde\",\n",
    "                                               \"Name_norm\":\"name\"}),\n",
    "               on=\"kommunen_id_start\", how=\"left\"))\n",
    "\n",
    "# -------------------- Compute shares & scaled 2043 --------------------\n",
    "# Guard against division by zero: if the group total is 0 or NaN, set share=0 and scaled=0\n",
    "den = work[\"population_2024_gemeinde\"].replace({0: np.nan})\n",
    "share = work[\"population_2024_kommune\"] / den\n",
    "work[\"weight_of_single_kommune_among_gemeinde\"] = (share.fillna(0) * 100)  # percent\n",
    "work[\"population_2043_gemeinde\"] = pd.to_numeric(work[\"population_2043_gemeinde\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "work[\"scaled_population_2043_kommune\"] = (\n",
    "    work[\"population_2043_gemeinde\"] * (work[\"weight_of_single_kommune_among_gemeinde\"] / 100.0)\n",
    ").round(0).astype(int)\n",
    "\n",
    "# -------------------- Final columns & save --------------------\n",
    "result = work[[\n",
    "    \"kommunen_id\",                        # 12-digit\n",
    "    \"kommunen_id_start\",                  # 5-digit prefix\n",
    "    \"name\",                               # from the prefix row\n",
    "    \"population_2024_kommune\",            # current pop by commune (from census_2_pop)\n",
    "    \"population_2024_gemeinde\",           # sum over the prefix\n",
    "    \"weight_of_single_kommune_among_gemeinde\",  # percent\n",
    "    \"population_2043_gemeinde\",           # PDF 2043 per prefix\n",
    "    \"scaled_population_2043_kommune\"      # allocated 2043 per commune\n",
    "]].copy()\n",
    "\n",
    "# Optional: tidy types / rounding\n",
    "result[\"weight_of_single_kommune_among_gemeinde\"] = result[\"weight_of_single_kommune_among_gemeinde\"].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f1cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cleaned = result[[\"kommunen_id\", \"population_2024_kommune\", \"scaled_population_2043_kommune\"]]\n",
    "result_cleaned = result_cleaned.rename(\n",
    "    columns={\n",
    "        \"population_2024_kommune\": \"pop_2024\",\n",
    "        \"scaled_population_2043_kommune\": \"pop_2043\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc46791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def normalize_id(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Return 12-digit string IDs (digits only, left-padded). Drop invalid.\"\"\"\n",
    "    s = (series.astype(str)\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\D\", \"\", regex=True)\n",
    "               .str.zfill(12))\n",
    "    return s.where(s.str.fullmatch(r\"\\d{12}\"))\n",
    "\n",
    "# -------------------- Inputs --------------------\n",
    "# result_cleaned must have: kommunen_id, pop_2024, pop_2043\n",
    "# census_df must have: commune_id, sex, age_class, weight\n",
    "# If you already have them in memory, you can skip these reads.\n",
    "# result_cleaned = pd.read_csv(\"result_cleaned.csv\", dtype={\"kommunen_id\": str})\n",
    "# census_df = pd.read_csv(\"census_data.csv\", dtype={\"commune_id\": str})\n",
    "\n",
    "# --- Normalize IDs and clean types\n",
    "result_cleaned[\"kommunen_id\"] = normalize_id(result_cleaned[\"kommunen_id\"])\n",
    "result_cleaned = result_cleaned[result_cleaned[\"kommunen_id\"].notna()].copy()\n",
    "\n",
    "census_2024_df[\"commune_id_norm\"] = normalize_id(census_2024_df[\"commune_id\"])\n",
    "census_2024_df = census_2024_df[census_2024_df[\"commune_id_norm\"].notna()].copy()\n",
    "census_2024_df[\"weight\"] = pd.to_numeric(census_2024_df[\"weight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -------------------- 1) Enumerate the 26 combinations --------------------\n",
    "all_combos = (\n",
    "    census_2024_df[[\"sex\", \"age_class\"]]\n",
    "      .drop_duplicates()\n",
    "      .sort_values([\"sex\", \"age_class\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "# Sanity: we expect 26 distinct combos total\n",
    "n_combos = len(all_combos)\n",
    "if n_combos != 26:\n",
    "    print(f\"WARNING: expected 26 (sex, age_class) combos, found {n_combos}. Proceeding with found combos.\")\n",
    "\n",
    "# -------------------- 2) Compute per-(commune_id, combo) weights & fractions --------------------\n",
    "combo_weights = (\n",
    "    census_2024_df\n",
    "      .groupby([\"commune_id_norm\", \"sex\", \"age_class\"], dropna=False)[\"weight\"]\n",
    "      .sum(min_count=1)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "totals_per_commune = (\n",
    "    combo_weights\n",
    "      .groupby(\"commune_id_norm\", dropna=False)[\"weight\"]\n",
    "      .sum(min_count=1)\n",
    "      .rename(\"total_weight_commune\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "combo_weights = combo_weights.merge(totals_per_commune, on=\"commune_id_norm\", how=\"left\")\n",
    "\n",
    "# Fraction per combo (guard against division by zero)\n",
    "combo_weights[\"fraction_2024\"] = (\n",
    "    combo_weights[\"weight\"] / combo_weights[\"total_weight_commune\"].replace({0: np.nan})\n",
    ").fillna(0.0)\n",
    "\n",
    "# -------------------- 3) Ensure every commune has all combos (fill missing with 0) --------------------\n",
    "communes = result_cleaned[[\"kommunen_id\"]].drop_duplicates().rename(columns={\"kommunen_id\": \"commune_id_norm\"})\n",
    "grid = communes.assign(key=1).merge(all_combos.assign(key=1), on=\"key\").drop(columns=\"key\")\n",
    "\n",
    "grid = grid.merge(\n",
    "    combo_weights[[\"commune_id_norm\", \"sex\", \"age_class\", \"fraction_2024\"]],\n",
    "    on=[\"commune_id_norm\", \"sex\", \"age_class\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "grid[\"fraction_2024\"] = grid[\"fraction_2024\"].fillna(0.0)\n",
    "\n",
    "# OPTIONAL EVEN-SPLIT FALLBACK:\n",
    "# If a commune has total_weight_commune == 0 (i.e., no data at all), you might want to split evenly across combos:\n",
    "# zero_data_communes = grid.groupby(\"commune_id_norm\")[\"fraction_2024\"].sum().reset_index()\n",
    "# zero_data_communes = zero_data_communes[zero_data_communes[\"fraction_2024\"] == 0][\"commune_id_norm\"]\n",
    "# grid.loc[grid[\"commune_id_norm\"].isin(zero_data_communes), \"fraction_2024\"] = 1.0 / n_combos\n",
    "\n",
    "# -------------------- 4) Expand result_cleaned (26 rows per commune) and scale pops --------------------\n",
    "expanded = (\n",
    "    grid.merge(\n",
    "        result_cleaned.rename(columns={\"kommunen_id\": \"commune_id_norm\"}),\n",
    "        on=\"commune_id_norm\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "expanded[\"pop_2024_by_combo\"] = expanded[\"pop_2024\"] * expanded[\"fraction_2024\"]\n",
    "expanded[\"pop_2043_by_combo\"] = expanded[\"pop_2043\"] * expanded[\"fraction_2024\"]\n",
    "\n",
    "# -------------------- 5) Validations --------------------\n",
    "# A) Fractions per commune should sum to 1 (or 0 if truly no data and no fallback)\n",
    "frac_sums = expanded.groupby(\"commune_id_norm\")[\"fraction_2024\"].sum().reset_index()\n",
    "bad_fracs = frac_sums[~np.isclose(frac_sums[\"fraction_2024\"], 1.0, atol=1e-8) & (frac_sums[\"fraction_2024\"] != 0)]\n",
    "if not bad_fracs.empty:\n",
    "    print(\"WARNING: Some communes have fractions not summing to 1 (and not 0). Examples:\")\n",
    "    print(bad_fracs.head())\n",
    "\n",
    "# B) Check that sums of distributed pops match originals (within tolerance)\n",
    "check_2024 = (\n",
    "    expanded.groupby(\"commune_id_norm\")[\"pop_2024_by_combo\"].sum().reset_index()\n",
    "    .merge(result_cleaned.rename(columns={\"kommunen_id\":\"commune_id_norm\"})[[\"commune_id_norm\",\"pop_2024\"]],\n",
    "           on=\"commune_id_norm\", how=\"left\")\n",
    ")\n",
    "check_2024[\"diff_2024\"] = check_2024[\"pop_2024_by_combo\"] - check_2024[\"pop_2024\"]\n",
    "if not np.allclose(check_2024[\"diff_2024\"], 0.0, atol=1e-6, rtol=1e-10):\n",
    "    print(\"WARNING: pop_2024_by_combo does not perfectly sum back to pop_2024 for some communes.\")\n",
    "\n",
    "check_2043 = (\n",
    "    expanded.groupby(\"commune_id_norm\")[\"pop_2043_by_combo\"].sum().reset_index()\n",
    "    .merge(result_cleaned.rename(columns={\"kommunen_id\":\"commune_id_norm\"})[[\"commune_id_norm\",\"pop_2043\"]],\n",
    "           on=\"commune_id_norm\", how=\"left\")\n",
    ")\n",
    "check_2043[\"diff_2043\"] = check_2043[\"pop_2043_by_combo\"] - check_2043[\"pop_2043\"]\n",
    "if not np.allclose(check_2043[\"diff_2043\"], 0.0, atol=1e-6, rtol=1e-10):\n",
    "    print(\"WARNING: pop_2043_by_combo does not perfectly sum back to pop_2043 for some communes.\")\n",
    "\n",
    "# -------------------- 6) Final tidy --------------------\n",
    "result_expanded = expanded[[\n",
    "    \"commune_id_norm\",  # == kommunen_id (12 digits)\n",
    "    \"sex\",\n",
    "    \"age_class\",\n",
    "    \"fraction_2024\",\n",
    "    \"pop_2024_by_combo\",\n",
    "    \"pop_2043_by_combo\",\n",
    "    \"pop_2024\",\n",
    "    \"pop_2043\",\n",
    "]].rename(columns={\"commune_id_norm\": \"kommunen_id\"})\n",
    "\n",
    "# (Optional) Round to integers if you need person counts:\n",
    "# result_expanded[\"pop_2024_by_combo\"] = result_expanded[\"pop_2024_by_combo\"].round(0).astype(int)\n",
    "# result_expanded[\"pop_2043_by_combo\"] = result_expanded[\"pop_2043_by_combo\"].round(0).astype(int)\n",
    "\n",
    "# Save if desired\n",
    "# result_expanded.to_csv(\"result_expanded_26_combos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc146136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kommunen_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_class</th>\n",
       "      <th>fraction_2024</th>\n",
       "      <th>pop_2024_by_combo</th>\n",
       "      <th>pop_2043_by_combo</th>\n",
       "      <th>pop_2024</th>\n",
       "      <th>pop_2043</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>2405.370527</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>2354.147019</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>6</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>2921.874224</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3222.812329</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>1897.404080</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>1411.847918</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>3920.732615</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>0.033759</td>\n",
       "      <td>4761.0</td>\n",
       "      <td>5080.731623</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>30</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>10447.0</td>\n",
       "      <td>11148.582916</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>0.064561</td>\n",
       "      <td>9105.0</td>\n",
       "      <td>9716.459026</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>50</td>\n",
       "      <td>0.096916</td>\n",
       "      <td>13668.0</td>\n",
       "      <td>14585.893681</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>65</td>\n",
       "      <td>0.049110</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>7391.125230</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>female</td>\n",
       "      <td>75</td>\n",
       "      <td>0.055457</td>\n",
       "      <td>7821.0</td>\n",
       "      <td>8346.230208</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016975</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>2554.772423</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>2464.064129</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "      <td>0.020499</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>3085.149154</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>10</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>3496.004368</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2134.312801</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>1501.489055</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>091610000000</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>0.033660</td>\n",
       "      <td>4747.0</td>\n",
       "      <td>5065.791433</td>\n",
       "      <td>141029</td>\n",
       "      <td>150500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kommunen_id     sex  age_class  fraction_2024  pop_2024_by_combo  \\\n",
       "0   091610000000  female          0       0.015983             2254.0   \n",
       "1   091610000000  female          3       0.015642             2206.0   \n",
       "2   091610000000  female          6       0.019414             2738.0   \n",
       "3   091610000000  female         10       0.021414             3020.0   \n",
       "4   091610000000  female         15       0.012607             1778.0   \n",
       "5   091610000000  female         18       0.009381             1323.0   \n",
       "6   091610000000  female         20       0.026051             3674.0   \n",
       "7   091610000000  female         25       0.033759             4761.0   \n",
       "8   091610000000  female         30       0.074077            10447.0   \n",
       "9   091610000000  female         40       0.064561             9105.0   \n",
       "10  091610000000  female         50       0.096916            13668.0   \n",
       "11  091610000000  female         65       0.049110             6926.0   \n",
       "12  091610000000  female         75       0.055457             7821.0   \n",
       "13  091610000000    male          0       0.016975             2394.0   \n",
       "14  091610000000    male          3       0.016373             2309.0   \n",
       "15  091610000000    male          6       0.020499             2891.0   \n",
       "16  091610000000    male         10       0.023229             3276.0   \n",
       "17  091610000000    male         15       0.014181             2000.0   \n",
       "18  091610000000    male         18       0.009977             1407.0   \n",
       "19  091610000000    male         20       0.033660             4747.0   \n",
       "\n",
       "    pop_2043_by_combo  pop_2024  pop_2043  \n",
       "0         2405.370527    141029    150500  \n",
       "1         2354.147019    141029    150500  \n",
       "2         2921.874224    141029    150500  \n",
       "3         3222.812329    141029    150500  \n",
       "4         1897.404080    141029    150500  \n",
       "5         1411.847918    141029    150500  \n",
       "6         3920.732615    141029    150500  \n",
       "7         5080.731623    141029    150500  \n",
       "8        11148.582916    141029    150500  \n",
       "9         9716.459026    141029    150500  \n",
       "10       14585.893681    141029    150500  \n",
       "11        7391.125230    141029    150500  \n",
       "12        8346.230208    141029    150500  \n",
       "13        2554.772423    141029    150500  \n",
       "14        2464.064129    141029    150500  \n",
       "15        3085.149154    141029    150500  \n",
       "16        3496.004368    141029    150500  \n",
       "17        2134.312801    141029    150500  \n",
       "18        1501.489055    141029    150500  \n",
       "19        5065.791433    141029    150500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_expanded.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aced7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = result_expanded.rename(\n",
    "    columns={\n",
    "        \"kommunen_id\": \"commune_id\",\n",
    "        \"pop_2043_by_combo\": \"weight\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636577b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=final_result[[\"commune_id\", \"sex\",\"age_class\",\"weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b496c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pop_munich_2045 = pd.read_csv(\"processed_pop_munich_2045.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d538f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commune_id</th>\n",
       "      <th>age_start</th>\n",
       "      <th>age_end</th>\n",
       "      <th>total_2045</th>\n",
       "      <th>predicted_female_share_2045</th>\n",
       "      <th>female_2045</th>\n",
       "      <th>male_2045</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91620000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>56184</td>\n",
       "      <td>0.487231</td>\n",
       "      <td>27375</td>\n",
       "      <td>28809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91620000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>50839</td>\n",
       "      <td>0.494434</td>\n",
       "      <td>25137</td>\n",
       "      <td>25702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91620000000</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>62569</td>\n",
       "      <td>0.490813</td>\n",
       "      <td>30710</td>\n",
       "      <td>31859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91620000000</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>74144</td>\n",
       "      <td>0.488693</td>\n",
       "      <td>36234</td>\n",
       "      <td>37910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91620000000</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>44982</td>\n",
       "      <td>0.483929</td>\n",
       "      <td>21768</td>\n",
       "      <td>23214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    commune_id  age_start  age_end  total_2045  predicted_female_share_2045  \\\n",
       "0  91620000000          0        2       56184                     0.487231   \n",
       "1  91620000000          3        5       50839                     0.494434   \n",
       "2  91620000000          6        9       62569                     0.490813   \n",
       "3  91620000000         10       14       74144                     0.488693   \n",
       "4  91620000000         15       17       44982                     0.483929   \n",
       "\n",
       "   female_2045  male_2045  \n",
       "0        27375      28809  \n",
       "1        25137      25702  \n",
       "2        30710      31859  \n",
       "3        36234      37910  \n",
       "4        21768      23214  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_pop_munich_2045.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4952ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct sex in result_final: ['female', 'male']\n",
      "Distinct sex in updates_long: ['female', 'male']\n",
      "Potential key matches: 26 out of 26 update keys and 28548 result keys\n",
      "Rows that will be updated: 26\n",
      "        sum_in_result_final  sum_from_updates\n",
      "sex                                          \n",
      "female             937453.0            937453\n",
      "male               892068.0            892068\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def normalize_id(s: pd.Series) -> pd.Series:\n",
    "    return (s.astype(str).str.strip().str.replace(r\"\\D\", \"\", regex=True).str.zfill(12))\n",
    "\n",
    "def normalize_sex(s: pd.Series) -> pd.Series:\n",
    "    # map a variety of spellings to {'female','male'}; everything else -> lowercased as-is\n",
    "    mapping = {\n",
    "        \"f\":\"female\",\"w\":\"female\",\"weiblich\":\"female\",\"female\":\"female\",\n",
    "        \"m\":\"male\",\"mann\":\"male\",\"maennlich\":\"male\",\"männlich\":\"male\",\"male\":\"male\"\n",
    "    }\n",
    "    return s.astype(str).str.strip().str.lower().map(mapping).fillna(s.astype(str).str.strip().str.lower())\n",
    "\n",
    "# ---------- 0) Make safe copies ----------\n",
    "result_final = final_result.copy()\n",
    "processed_pop_munich_2045 = processed_pop_munich_2045.copy()\n",
    "\n",
    "# ---------- 1) Normalize keys / types ----------\n",
    "# result_final\n",
    "if \"kommunen_id\" in result_final.columns and \"commune_id\" not in result_final.columns:\n",
    "    result_final = result_final.rename(columns={\"kommunen_id\":\"commune_id\"})\n",
    "result_final[\"commune_id\"] = normalize_id(result_final[\"commune_id\"])\n",
    "result_final[\"sex\"] = normalize_sex(result_final[\"sex\"])\n",
    "result_final[\"age_class\"] = pd.to_numeric(result_final[\"age_class\"], errors=\"coerce\").astype(\"Int64\")\n",
    "result_final[\"weight\"] = pd.to_numeric(result_final[\"weight\"], errors=\"coerce\")\n",
    "\n",
    "# processed_pop_munich_2045\n",
    "processed_pop_munich_2045[\"commune_id\"] = normalize_id(processed_pop_munich_2045[\"commune_id\"])\n",
    "processed_pop_munich_2045[\"age_start\"] = pd.to_numeric(processed_pop_munich_2045[\"age_start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ---------- 2) Reshape Munich table to long by sex ----------\n",
    "updates_long = (\n",
    "    processed_pop_munich_2045\n",
    "      .melt(id_vars=[\"commune_id\",\"age_start\"],\n",
    "            value_vars=[\"female_2045\",\"male_2045\"],\n",
    "            var_name=\"sex_var\", value_name=\"weight_new\")\n",
    "      .assign(sex=lambda df: df[\"sex_var\"].str.replace(\"_2045\",\"\",regex=False))\n",
    "      .rename(columns={\"age_start\":\"age_class\"})\n",
    "      [[\"commune_id\",\"sex\",\"age_class\",\"weight_new\"]]\n",
    ")\n",
    "\n",
    "# If there are accidental duplicates per key, collapse them (sum)\n",
    "updates_long = (updates_long\n",
    "                .groupby([\"commune_id\",\"sex\",\"age_class\"], as_index=False)[\"weight_new\"]\n",
    "                .sum())\n",
    "\n",
    "# ---------- 3) Check key alignment BEFORE merge ----------\n",
    "print(\"Distinct sex in result_final:\", sorted(result_final[\"sex\"].dropna().unique())[:10])\n",
    "print(\"Distinct sex in updates_long:\", sorted(updates_long[\"sex\"].dropna().unique())[:10])\n",
    "\n",
    "rf_keys = set(zip(result_final[\"commune_id\"], result_final[\"sex\"], result_final[\"age_class\"]))\n",
    "up_keys = set(zip(updates_long[\"commune_id\"], updates_long[\"sex\"], updates_long[\"age_class\"]))\n",
    "matches = rf_keys & up_keys\n",
    "print(\"Potential key matches:\", len(matches), \"out of\", len(up_keys), \"update keys and\", len(rf_keys), \"result keys\")\n",
    "\n",
    "if len(matches) == 0:\n",
    "    # Show a few example keys that fail to match\n",
    "    only_in_updates = list(up_keys - rf_keys)[:10]\n",
    "    only_in_result  = list(rf_keys - up_keys)[:10]\n",
    "    print(\"Examples of update keys not in result_final:\", only_in_updates)\n",
    "    print(\"Examples of result_final keys not in updates:\", only_in_result)\n",
    "\n",
    "# ---------- 4) Merge & overwrite weight where we have a match ----------\n",
    "merged = result_final.merge(\n",
    "    updates_long,\n",
    "    on=[\"commune_id\",\"sex\",\"age_class\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep old for reference if you want:\n",
    "# merged[\"weight_old\"] = merged[\"weight\"]\n",
    "\n",
    "updated_count = merged[\"weight_new\"].notna().sum()\n",
    "print(\"Rows that will be updated:\", updated_count)\n",
    "\n",
    "merged[\"weight\"] = np.where(merged[\"weight_new\"].notna(), merged[\"weight_new\"], merged[\"weight\"])\n",
    "merged = merged.drop(columns=[\"weight_new\"])\n",
    "\n",
    "# This is your updated result_final:\n",
    "result_final = merged\n",
    "\n",
    "# --- Optional: verify Munich totals match the source after update\n",
    "muc_id = \"091620000000\"\n",
    "check = (\n",
    "    result_final[result_final[\"commune_id\"] == muc_id]\n",
    "      .groupby(\"sex\")[\"weight\"].sum()\n",
    "      .rename(\"sum_in_result_final\")\n",
    "      .to_frame()\n",
    "      .join(\n",
    "          updates_long[updates_long[\"commune_id\"] == muc_id]\n",
    "            .groupby(\"sex\")[\"weight_new\"].sum()\n",
    "            .rename(\"sum_from_updates\"),\n",
    "          how=\"left\"\n",
    "      )\n",
    ")\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00a2b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final[\"weight\"] = result_final[\"weight\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf9ea9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_2 = result_final.copy()\n",
    "final_result_2[\"commune_id\"] = final_result_2[\"commune_id\"].astype(str)\n",
    "subset = final_result_2[final_result_2[\"commune_id\"] == \"091620000000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4b30ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commune_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_class</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>27375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>25137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>6</td>\n",
       "      <td>30710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "      <td>36234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>21768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>18692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>57209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>85019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>30</td>\n",
       "      <td>168660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>117174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>50</td>\n",
       "      <td>173618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>65</td>\n",
       "      <td>81397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>female</td>\n",
       "      <td>75</td>\n",
       "      <td>94460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>28809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>25702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "      <td>31859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>10</td>\n",
       "      <td>37910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>23214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>19564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>58690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>84286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>169950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>40</td>\n",
       "      <td>111574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>50</td>\n",
       "      <td>169505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>65</td>\n",
       "      <td>65181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>091620000000</td>\n",
       "      <td>male</td>\n",
       "      <td>75</td>\n",
       "      <td>65824.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      commune_id     sex  age_class    weight\n",
       "26  091620000000  female          0   27375.0\n",
       "27  091620000000  female          3   25137.0\n",
       "28  091620000000  female          6   30710.0\n",
       "29  091620000000  female         10   36234.0\n",
       "30  091620000000  female         15   21768.0\n",
       "31  091620000000  female         18   18692.0\n",
       "32  091620000000  female         20   57209.0\n",
       "33  091620000000  female         25   85019.0\n",
       "34  091620000000  female         30  168660.0\n",
       "35  091620000000  female         40  117174.0\n",
       "36  091620000000  female         50  173618.0\n",
       "37  091620000000  female         65   81397.0\n",
       "38  091620000000  female         75   94460.0\n",
       "39  091620000000    male          0   28809.0\n",
       "40  091620000000    male          3   25702.0\n",
       "41  091620000000    male          6   31859.0\n",
       "42  091620000000    male         10   37910.0\n",
       "43  091620000000    male         15   23214.0\n",
       "44  091620000000    male         18   19564.0\n",
       "45  091620000000    male         20   58690.0\n",
       "46  091620000000    male         25   84286.0\n",
       "47  091620000000    male         30  169950.0\n",
       "48  091620000000    male         40  111574.0\n",
       "49  091620000000    male         50  169505.0\n",
       "50  091620000000    male         65   65181.0\n",
       "51  091620000000    male         75   65824.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47d9e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final[\"commune_id\"] = result_final[\"commune_id\"].astype(\"string\")\n",
    "\n",
    "result_final.to_csv(\"census_data_2043.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6287eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commune_id    object\n",
      "sex           object\n",
      "age_class      Int64\n",
      "weight         int64\n",
      "dtype: object\n",
      "  commune_id  sex age_class weight\n",
      "0        str  str       int    int\n",
      "1        str  str       int    int\n",
      "2        str  str       int    int\n",
      "3        str  str       int    int\n",
      "4        str  str       int    int\n",
      "commune_id    str\n",
      "sex           str\n",
      "age_class     int\n",
      "weight        int\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_12620/1332315755.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  types_df = result_final.applymap(lambda x: type(x).__name__)\n"
     ]
    }
   ],
   "source": [
    "# 1) Column dtypes (pandas dtypes)\n",
    "print(result_final.dtypes)\n",
    "\n",
    "# 2) Per-cell Python type (by row) — creates a parallel DataFrame of type names\n",
    "types_df = result_final.applymap(lambda x: type(x).__name__)\n",
    "print(types_df.head())          # first rows of types\n",
    "print(types_df.iloc[0])         # types of row 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a5b2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commune_id         object\n",
      "sex                object\n",
      "age_class           int64\n",
      "weight              int64\n",
      "commune_id_norm    object\n",
      "dtype: object\n",
      "  commune_id  sex age_class weight commune_id_norm\n",
      "0        str  str       int    int             str\n",
      "1        str  str       int    int             str\n",
      "2        str  str       int    int             str\n",
      "3        str  str       int    int             str\n",
      "4        str  str       int    int             str\n",
      "commune_id         str\n",
      "sex                str\n",
      "age_class          int\n",
      "weight             int\n",
      "commune_id_norm    str\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_12620/3392168973.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  types_df = census_2024_df.applymap(lambda x: type(x).__name__)\n"
     ]
    }
   ],
   "source": [
    "print(census_2024_df.dtypes)\n",
    "\n",
    "# 2) Per-cell Python type (by row) — creates a parallel DataFrame of type names\n",
    "types_df = census_2024_df.applymap(lambda x: type(x).__name__)\n",
    "print(types_df.head())          # first rows of types\n",
    "print(types_df.iloc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b77560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
